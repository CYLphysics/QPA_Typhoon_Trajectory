{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import random \n",
    "import qadence as qd\n",
    "import numpy as np \n",
    "import time \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "# from torchsummary import summary\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.dirname(current_dir))\n",
    "\n",
    "from code_base.qpa_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)  # Set PyTorch seed\n",
    "    np.random.seed(seed)      # Set NumPy seed\n",
    "    random.seed(seed)         # Set Python random seed\n",
    "\n",
    "    # Ensure reproducibility for CUDA (if using GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # Disable to ensure consistent runs\n",
    "\n",
    "# Set a fixed seed\n",
    "set_seed(58) #56 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing for the Typhoon dataset\n",
    "\n",
    "Before diving into the exciting Quantum Parameter Adaptation section, we first need to preprocess the data. Since data processing is not the main focus of this project, we will only provide a brief overview. Interested readers can refer to the original paper ([here](https://www.researchgate.net/publication/357911189_AM-ConvGRU_a_spatio-temporal_model_for_typhoon_path_prediction)) for a detailed explanation and the full classical machine learning model.\n",
    "\n",
    "<img src=\"https://github.com/CYLphysics/CYLphysics.github.io/blob/master/assets/images/figure/total_data.png?raw=true\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# forecast 24-hour lead time \n",
    "pre_seq = 4\n",
    "batch_size = 128\n",
    "epochs = 256\n",
    "min_val_loss = 100\n",
    "model_name = '../results/model_saver/QPA_ck_64_qnn_depth_20.pkl'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahead_time: 0 (8406, 1, 4, 31, 31)\n",
      "ahead_time: 1 (8406, 1, 4, 31, 31)\n",
      "ahead_time: 2 (8406, 1, 4, 31, 31)\n",
      "ahead_time: 3 (8406, 1, 4, 31, 31)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/CMA_train_'+str(pre_seq*6)+'h.csv', header=None)\n",
    "test = pd.read_csv('../data/CMA_test_'+str(pre_seq*6)+'h.csv', header=None)\n",
    "\n",
    "\n",
    "CLIPER_feature =  pd.concat((train, test), axis=0)\n",
    "CLIPER_feature.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "X_wide_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X_wide = X_wide_scaler.fit_transform(CLIPER_feature.iloc[:, 6:])\n",
    "X_wide_train = X_wide[0: train.shape[0], :]\n",
    "\n",
    "y = y_scaler.fit_transform(CLIPER_feature.loc[:, 3:4])\n",
    "y_train = y[0: train.shape[0], :]\n",
    "\n",
    "\n",
    "reanalysis_type = 'z'\n",
    "# 0 means now \n",
    "# 1 means 6-hour ago\n",
    "# 2 means 12-hour ago\n",
    "ahead_times = [0,1,2,3]\n",
    "pressures = [1000, 750, 500, 250]\n",
    "sequential_reanalysis_list = []\n",
    "reanalysis_test_dict = {}\n",
    "X_deep_scaler_dict = {}\n",
    "\n",
    "\n",
    "for ahead_time in ahead_times:\n",
    "\n",
    "    reanalysis_list = []\n",
    "    for pressure in pressures:\n",
    "        \n",
    "        folder = None\n",
    "        if ahead_time == 0:\n",
    "            folder = reanalysis_type\n",
    "        else:\n",
    "            folder = reanalysis_type + '_' + str(ahead_time*6)\n",
    "        train_reanalysis_csv = pd.read_csv('../data/ERA_Interim/'+folder+'/'+reanalysis_type+str(pressure)+'_train_31_31.csv', header=None)\n",
    "        test_reanalysis_csv = pd.read_csv('../data/ERA_Interim/'+folder+'/'+reanalysis_type+str(pressure)+'_test_31_31.csv', header=None)\n",
    "        \n",
    "        train_reanalysis = train_reanalysis_csv[train_reanalysis_csv[0].isin(train[0].unique())]\n",
    "        test_reanalysis = test_reanalysis_csv[test_reanalysis_csv[0].isin(test[0].unique())]\n",
    "        reanalysis_test_dict[reanalysis_type+str(pressure)+str(ahead_time)] = test_reanalysis\n",
    "        \n",
    "        reanalysis =  pd.concat((train_reanalysis, test_reanalysis), axis=0)\n",
    "        reanalysis.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        scaler_name = reanalysis_type +str(pressure) + str(ahead_time)\n",
    "        X_deep_scaler_dict[scaler_name] = MinMaxScaler()\n",
    "        X_deep = X_deep_scaler_dict[scaler_name] .fit_transform(reanalysis.loc[:, 5:])\n",
    "        \n",
    "        X_deep_final = X_deep[0: train.shape[0], :].reshape(-1, 1, 1, 31, 31)\n",
    "        reanalysis_list.append(X_deep_final)\n",
    "    \n",
    "    X_deep_temp = np.concatenate(reanalysis_list[:], axis=2)\n",
    "    print(\"ahead_time:\", ahead_time, X_deep_temp.shape)\n",
    "    sequential_reanalysis_list.append(X_deep_temp)\n",
    "\n",
    "X_deep_train = np.concatenate(sequential_reanalysis_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of training set and validation set\n",
    "\n",
    "The typhoon data from 2000 to 2014 is used for training, while data from 2015 to 2018 is used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLoader(Data.Dataset):\n",
    "    def __init__(self, X_wide_train, X_deep_train, y_train):\n",
    "        self.X_wide_train = X_wide_train\n",
    "        self.X_deep_train = X_deep_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return [self.X_wide_train[index], self.X_deep_train[index]], self.y_train[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_wide_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_index = [*range(0, len(X_wide_train))]\n",
    "\n",
    "train_index, val_index, _, _, = train_test_split(full_train_index,full_train_index,test_size=0.1)\n",
    "\n",
    "\n",
    "train_dataset = torch.utils.data.DataLoader(\n",
    "    TrainLoader(X_wide_train[train_index], X_deep_train[train_index], y_train[train_index]), \n",
    "                                                 batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "val_dataset = torch.utils.data.DataLoader(\n",
    "    TrainLoader(X_wide_train[val_index], X_deep_train[val_index], y_train[val_index]), \n",
    "                                                 batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Parameter Adaptation (QPA)\n",
    "\n",
    "The implementation of Quantum Parameter Adaptation (QPA) is provided in `code_base/qpa_utils.py`. \n",
    "\n",
    "<img src=\"https://github.com/CYLphysics/CYLphysics.github.io/blob/master/assets/images/figure/qeel.png?raw=true\"/>\n",
    "\n",
    "\n",
    "<!-- Interestingly, the core concept of the QPA is that, we compress only the training parameters during training, using QML technique (more detail in the technical report). Thus, during the inference stage, ie.. the daily usage of the trained model, do not require the usage of quantum computer, since the training result of QPA is a pure classical model. QPA is a Quantum-Train-based (QT-based) method, the comparison of the computational scheme for conventional QML and QT is shown below. Furthermore, as one may observe, the QT-based method don't require the data encoding part of the quantum circuit, since the data is inputted directly into the classical model, thus QT (QPA) also eliminate the issue of data encoding, which is very challenging when the input data is large. Lastly, QT (QPA) utlize the power of Hilbert space, assuming the polynomial number of QNN layers are used, training the classical model with $m$ parameters only requires $polylog(m)$ parameters. (more detail in the section 2 of the technical report.) -->\n",
    " \n",
    "The core concept of QPA is that we compress only the training parameters during training using Quantum Machine Learning (QML) techniques (see the technical report for more details). During inference—i.e., the daily usage of the trained model—no quantum computing resources are required, as the output of QPA is a purely classical model.\n",
    "\n",
    "QPA is a Quantum-Train-based (QT-based) method, and a comparison of the computational schemes between conventional QML and QT is shown below. Notably, QT-based methods do not require a quantum data encoding process, since the data is directly input into the classical model. This eliminates the data encoding challenge, which becomes increasingly difficult as the input data size grows.\n",
    "\n",
    "Furthermore, QT (QPA) leverages the power of Hilbert space. Assuming a polynomial number of Quantum Neural Network (QNN) layers are used, training a classical model with $ m $ parameters only requires $ polylog(m)$  parameters (see Section 2 of the technical report for further details).\n",
    "\n",
    "<img src=\"https://github.com/CYLphysics/CYLphysics.github.io/blob/master/assets/images/figure/qml_and_qt.png?raw=true\"/>\n",
    "\n",
    "\n",
    "<!-- Thus, in the below notebook block, although the original ML model have about 8399540 trainable parameters, one can see in our QPA only require 216398 parameters (under specific hyperparameter setting). This is only 2.57% of the original model. And the qubit usage is 8, as shown below. The calculation of the qubit usage can be found in the section 2 of the technical report. \n",
    " -->\n",
    "\n",
    "In the notebook block below, while the original machine learning model has 8,399,540 trainable parameters, our QPA approach—under a specific hyperparameter setting—requires only 216,398 parameters. This is merely 2.57% of the original model’s size, demonstrating significant parameter reduction. Additionally, the qubit usage is only 8, as shown below. The detailed calculation of qubit usage can be found in Section 2 of the technical report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/nn/modules/module.py:1145: UserWarning: Complex modules are a new feature under active development whose design may change, and some modules might not work as expected when using complex tensors as parameters or buffers. Please file an issue at https://github.com/pytorch/pytorch/issues/new?template=bug-report.yml if a complex module does not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trainable parameters in the current model:  216398\n",
      " # of required qubits in the current QPA setting:  8\n"
     ]
    }
   ],
   "source": [
    "net = Net() \n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4)\n",
    "total_steps = len(train_dataset) * epochs  \n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "\n",
    "print(\"# of trainable parameters in the current model: \",\n",
    "    sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    ")\n",
    "\n",
    "print(\" # of required qubits in the current QPA setting: \", \n",
    "      net.fc1.grand_hypernetwork[0].n_qubit\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/chenyuv2/QPA_Typhoon_Trajectory-main/code_base/qpa_utils.py:442: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:305.)\n",
      "  x = x.to(torch.float32).cuda()\n",
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs [1/256], cost:41.00s train_loss: 11.93839 val_loss: 0.98808\n",
      "epochs [2/256], cost:40.00s train_loss: 9.21993 val_loss: 0.92905\n",
      "epochs [3/256], cost:40.00s train_loss: 7.01862 val_loss: 0.70735\n",
      "epochs [4/256], cost:40.00s train_loss: 5.87121 val_loss: 0.61194\n",
      "epochs [5/256], cost:40.00s train_loss: 5.11536 val_loss: 0.59566\n",
      "epochs [6/256], cost:40.00s train_loss: 4.71794 val_loss: 0.51833\n",
      "epochs [7/256], cost:40.00s train_loss: 4.20430 val_loss: 0.49784\n",
      "epochs [8/256], cost:40.00s train_loss: 3.84581 val_loss: 0.48825\n",
      "epochs [9/256], cost:39.00s train_loss: 4.67258 val_loss: 0.50280\n",
      "epochs [10/256], cost:40.00s train_loss: 3.69485 val_loss: 0.39126\n",
      "epochs [11/256], cost:39.00s train_loss: 3.28804 val_loss: 0.39571\n",
      "epochs [12/256], cost:40.00s train_loss: 3.37599 val_loss: 0.31459\n",
      "epochs [13/256], cost:39.00s train_loss: 3.45126 val_loss: 0.35209\n",
      "epochs [14/256], cost:39.00s train_loss: 3.00901 val_loss: 0.37014\n",
      "epochs [15/256], cost:40.00s train_loss: 2.94327 val_loss: 0.31443\n",
      "epochs [16/256], cost:40.00s train_loss: 2.81616 val_loss: 0.24925\n",
      "epochs [17/256], cost:39.00s train_loss: 2.41010 val_loss: 0.25132\n",
      "epochs [18/256], cost:39.00s train_loss: 2.17753 val_loss: 0.27643\n",
      "epochs [19/256], cost:40.00s train_loss: 2.17728 val_loss: 0.23420\n",
      "epochs [20/256], cost:39.00s train_loss: 2.04233 val_loss: 0.23703\n",
      "epochs [21/256], cost:39.00s train_loss: 2.00239 val_loss: 0.26876\n",
      "epochs [22/256], cost:40.00s train_loss: 2.07478 val_loss: 0.20323\n",
      "epochs [23/256], cost:40.00s train_loss: 1.98252 val_loss: 0.19378\n",
      "epochs [24/256], cost:39.00s train_loss: 1.88833 val_loss: 0.20086\n",
      "epochs [25/256], cost:39.00s train_loss: 1.72816 val_loss: 0.21521\n",
      "epochs [26/256], cost:39.00s train_loss: 1.82630 val_loss: 0.22093\n",
      "epochs [27/256], cost:39.00s train_loss: 1.90111 val_loss: 0.20322\n",
      "epochs [28/256], cost:40.00s train_loss: 1.66710 val_loss: 0.19167\n",
      "epochs [29/256], cost:39.00s train_loss: 1.75250 val_loss: 0.22714\n",
      "epochs [30/256], cost:40.00s train_loss: 1.78702 val_loss: 0.19022\n",
      "epochs [31/256], cost:39.00s train_loss: 1.81697 val_loss: 0.19222\n",
      "epochs [32/256], cost:39.00s train_loss: 1.70422 val_loss: 0.19219\n",
      "epochs [33/256], cost:39.00s train_loss: 1.68240 val_loss: 0.19535\n",
      "epochs [34/256], cost:40.00s train_loss: 1.66929 val_loss: 0.18246\n",
      "epochs [35/256], cost:39.00s train_loss: 1.65601 val_loss: 0.17510\n",
      "epochs [36/256], cost:39.00s train_loss: 1.56848 val_loss: 0.17699\n",
      "epochs [37/256], cost:40.00s train_loss: 1.58060 val_loss: 0.17348\n",
      "epochs [38/256], cost:40.00s train_loss: 1.57710 val_loss: 0.17123\n",
      "epochs [39/256], cost:39.00s train_loss: 1.49906 val_loss: 0.18626\n",
      "epochs [40/256], cost:39.00s train_loss: 1.46628 val_loss: 0.19832\n",
      "epochs [41/256], cost:39.00s train_loss: 1.44556 val_loss: 0.17181\n",
      "epochs [42/256], cost:39.00s train_loss: 1.44654 val_loss: 0.17934\n",
      "epochs [43/256], cost:39.00s train_loss: 1.60217 val_loss: 0.17903\n",
      "epochs [44/256], cost:39.00s train_loss: 1.49973 val_loss: 0.16511\n",
      "epochs [45/256], cost:39.00s train_loss: 1.57219 val_loss: 0.18122\n",
      "epochs [46/256], cost:39.00s train_loss: 1.46499 val_loss: 0.16594\n",
      "epochs [47/256], cost:39.00s train_loss: 1.42275 val_loss: 0.15548\n",
      "epochs [48/256], cost:39.00s train_loss: 1.40737 val_loss: 0.17115\n",
      "epochs [49/256], cost:39.00s train_loss: 1.46133 val_loss: 0.17159\n",
      "epochs [50/256], cost:39.00s train_loss: 1.44921 val_loss: 0.15757\n",
      "epochs [51/256], cost:39.00s train_loss: 1.42889 val_loss: 0.16448\n",
      "epochs [52/256], cost:40.00s train_loss: 1.34267 val_loss: 0.14071\n",
      "epochs [53/256], cost:39.00s train_loss: 1.34375 val_loss: 0.13955\n",
      "epochs [54/256], cost:39.00s train_loss: 1.38368 val_loss: 0.14519\n",
      "epochs [55/256], cost:39.00s train_loss: 1.36215 val_loss: 0.15375\n",
      "epochs [56/256], cost:39.00s train_loss: 1.28388 val_loss: 0.14495\n",
      "epochs [57/256], cost:39.00s train_loss: 1.28959 val_loss: 0.13440\n",
      "epochs [58/256], cost:39.00s train_loss: 1.21913 val_loss: 0.14468\n",
      "epochs [59/256], cost:39.00s train_loss: 1.20764 val_loss: 0.13486\n",
      "epochs [60/256], cost:39.00s train_loss: 1.16729 val_loss: 0.13280\n",
      "epochs [61/256], cost:39.00s train_loss: 1.09993 val_loss: 0.11760\n",
      "epochs [62/256], cost:39.00s train_loss: 1.09592 val_loss: 0.11803\n",
      "epochs [63/256], cost:39.00s train_loss: 1.07541 val_loss: 0.12450\n",
      "epochs [64/256], cost:39.00s train_loss: 1.11581 val_loss: 0.14370\n",
      "epochs [65/256], cost:39.00s train_loss: 1.14119 val_loss: 0.12065\n",
      "epochs [66/256], cost:39.00s train_loss: 1.04760 val_loss: 0.12773\n",
      "epochs [67/256], cost:39.00s train_loss: 1.11891 val_loss: 0.15711\n",
      "epochs [68/256], cost:39.00s train_loss: 1.07920 val_loss: 0.12252\n",
      "epochs [69/256], cost:39.00s train_loss: 1.03999 val_loss: 0.13335\n",
      "epochs [70/256], cost:39.00s train_loss: 0.98703 val_loss: 0.11921\n",
      "epochs [71/256], cost:39.00s train_loss: 1.14845 val_loss: 0.12159\n",
      "epochs [72/256], cost:38.00s train_loss: 1.12082 val_loss: 0.13428\n",
      "epochs [73/256], cost:39.00s train_loss: 0.97554 val_loss: 0.10972\n",
      "epochs [74/256], cost:38.00s train_loss: 0.90907 val_loss: 0.12852\n",
      "epochs [75/256], cost:39.00s train_loss: 1.00347 val_loss: 0.11841\n",
      "epochs [76/256], cost:38.00s train_loss: 1.07888 val_loss: 0.11752\n",
      "epochs [77/256], cost:39.00s train_loss: 1.26452 val_loss: 0.12637\n",
      "epochs [78/256], cost:39.00s train_loss: 1.01547 val_loss: 0.10359\n",
      "epochs [79/256], cost:39.00s train_loss: 0.87895 val_loss: 0.10376\n",
      "epochs [80/256], cost:39.00s train_loss: 0.90964 val_loss: 0.10102\n",
      "epochs [81/256], cost:39.00s train_loss: 0.95431 val_loss: 0.11699\n",
      "epochs [82/256], cost:38.00s train_loss: 0.91157 val_loss: 0.11826\n",
      "epochs [83/256], cost:39.00s train_loss: 0.86268 val_loss: 0.09997\n",
      "epochs [84/256], cost:39.00s train_loss: 0.84842 val_loss: 0.09489\n",
      "epochs [85/256], cost:38.00s train_loss: 0.84559 val_loss: 0.09810\n",
      "epochs [86/256], cost:39.00s train_loss: 0.79701 val_loss: 0.09273\n",
      "epochs [87/256], cost:38.00s train_loss: 0.88553 val_loss: 0.10400\n",
      "epochs [88/256], cost:38.00s train_loss: 1.04341 val_loss: 0.09550\n",
      "epochs [89/256], cost:38.00s train_loss: 0.84113 val_loss: 0.10505\n",
      "epochs [90/256], cost:38.00s train_loss: 0.88351 val_loss: 0.11010\n",
      "epochs [91/256], cost:38.00s train_loss: 0.79411 val_loss: 0.09426\n",
      "epochs [92/256], cost:39.00s train_loss: 0.80720 val_loss: 0.08843\n",
      "epochs [93/256], cost:39.00s train_loss: 0.74057 val_loss: 0.08485\n",
      "epochs [94/256], cost:39.00s train_loss: 0.74787 val_loss: 0.08140\n",
      "epochs [95/256], cost:38.00s train_loss: 0.76420 val_loss: 0.09497\n",
      "epochs [96/256], cost:38.00s train_loss: 0.82131 val_loss: 0.09491\n",
      "epochs [97/256], cost:38.00s train_loss: 0.93077 val_loss: 0.10658\n",
      "epochs [98/256], cost:39.00s train_loss: 0.75772 val_loss: 0.08881\n",
      "epochs [99/256], cost:38.00s train_loss: 0.76027 val_loss: 0.08900\n",
      "epochs [100/256], cost:39.00s train_loss: 0.70475 val_loss: 0.07940\n",
      "epochs [101/256], cost:38.00s train_loss: 0.70582 val_loss: 0.08613\n",
      "epochs [102/256], cost:38.00s train_loss: 0.72519 val_loss: 0.09329\n",
      "epochs [103/256], cost:39.00s train_loss: 0.78081 val_loss: 0.09314\n",
      "epochs [104/256], cost:39.00s train_loss: 0.69413 val_loss: 0.07644\n",
      "epochs [105/256], cost:39.00s train_loss: 0.75927 val_loss: 0.08687\n",
      "epochs [106/256], cost:38.00s train_loss: 0.73381 val_loss: 0.10681\n",
      "epochs [107/256], cost:39.00s train_loss: 0.74006 val_loss: 0.08810\n",
      "epochs [108/256], cost:38.00s train_loss: 0.73976 val_loss: 0.08162\n",
      "epochs [109/256], cost:39.00s train_loss: 0.74171 val_loss: 0.08042\n",
      "epochs [110/256], cost:38.00s train_loss: 0.71718 val_loss: 0.07969\n",
      "epochs [111/256], cost:39.00s train_loss: 0.72242 val_loss: 0.07339\n",
      "epochs [112/256], cost:38.00s train_loss: 0.71960 val_loss: 0.08836\n",
      "epochs [113/256], cost:39.00s train_loss: 0.73584 val_loss: 0.07278\n",
      "epochs [114/256], cost:38.00s train_loss: 0.65068 val_loss: 0.09274\n",
      "epochs [115/256], cost:38.00s train_loss: 0.67910 val_loss: 0.08044\n",
      "epochs [116/256], cost:38.00s train_loss: 0.69247 val_loss: 0.07476\n",
      "epochs [117/256], cost:39.00s train_loss: 0.68181 val_loss: 0.07235\n",
      "epochs [118/256], cost:39.00s train_loss: 0.63419 val_loss: 0.06836\n",
      "epochs [119/256], cost:38.00s train_loss: 0.59612 val_loss: 0.07024\n",
      "epochs [120/256], cost:38.00s train_loss: 0.61978 val_loss: 0.07877\n",
      "epochs [121/256], cost:38.00s train_loss: 0.63746 val_loss: 0.08695\n",
      "epochs [122/256], cost:38.00s train_loss: 0.81083 val_loss: 0.08525\n",
      "epochs [123/256], cost:38.00s train_loss: 0.74662 val_loss: 0.09026\n",
      "epochs [124/256], cost:38.00s train_loss: 0.69114 val_loss: 0.08004\n",
      "epochs [125/256], cost:38.00s train_loss: 0.63851 val_loss: 0.07059\n",
      "epochs [126/256], cost:38.00s train_loss: 0.68710 val_loss: 0.08562\n",
      "epochs [127/256], cost:38.00s train_loss: 0.65081 val_loss: 0.07852\n",
      "epochs [128/256], cost:39.00s train_loss: 0.60590 val_loss: 0.06611\n",
      "epochs [129/256], cost:39.00s train_loss: 0.58245 val_loss: 0.06458\n",
      "epochs [130/256], cost:38.00s train_loss: 0.56831 val_loss: 0.06780\n",
      "epochs [131/256], cost:38.00s train_loss: 0.59705 val_loss: 0.06982\n",
      "epochs [132/256], cost:38.00s train_loss: 0.62615 val_loss: 0.06630\n",
      "epochs [133/256], cost:38.00s train_loss: 0.62061 val_loss: 0.06754\n",
      "epochs [134/256], cost:38.00s train_loss: 0.65473 val_loss: 0.07393\n",
      "epochs [135/256], cost:39.00s train_loss: 0.59596 val_loss: 0.06260\n",
      "epochs [136/256], cost:38.00s train_loss: 0.56963 val_loss: 0.06439\n",
      "epochs [137/256], cost:38.00s train_loss: 0.61911 val_loss: 0.06900\n",
      "epochs [138/256], cost:38.00s train_loss: 0.61538 val_loss: 0.08545\n",
      "epochs [139/256], cost:38.00s train_loss: 0.64192 val_loss: 0.06915\n",
      "epochs [140/256], cost:38.00s train_loss: 0.63481 val_loss: 0.06872\n",
      "epochs [141/256], cost:38.00s train_loss: 0.56799 val_loss: 0.07105\n",
      "epochs [142/256], cost:39.00s train_loss: 0.57228 val_loss: 0.06235\n",
      "epochs [143/256], cost:39.00s train_loss: 0.54823 val_loss: 0.06215\n",
      "epochs [144/256], cost:38.00s train_loss: 0.57075 val_loss: 0.07018\n",
      "epochs [145/256], cost:38.00s train_loss: 0.54319 val_loss: 0.07526\n",
      "epochs [146/256], cost:38.00s train_loss: 0.55950 val_loss: 0.06253\n",
      "epochs [147/256], cost:38.00s train_loss: 0.60063 val_loss: 0.06311\n",
      "epochs [148/256], cost:38.00s train_loss: 0.56411 val_loss: 0.08666\n",
      "epochs [149/256], cost:39.00s train_loss: 0.56141 val_loss: 0.06064\n",
      "epochs [150/256], cost:38.00s train_loss: 0.55392 val_loss: 0.06791\n",
      "epochs [151/256], cost:38.00s train_loss: 0.53750 val_loss: 0.06863\n",
      "epochs [152/256], cost:39.00s train_loss: 0.51587 val_loss: 0.05585\n",
      "epochs [153/256], cost:38.00s train_loss: 0.52881 val_loss: 0.06184\n",
      "epochs [154/256], cost:38.00s train_loss: 0.51793 val_loss: 0.06440\n",
      "epochs [155/256], cost:38.00s train_loss: 0.51032 val_loss: 0.05770\n",
      "epochs [156/256], cost:38.00s train_loss: 0.54969 val_loss: 0.06267\n",
      "epochs [157/256], cost:38.00s train_loss: 0.57634 val_loss: 0.08196\n",
      "epochs [158/256], cost:38.00s train_loss: 0.61738 val_loss: 0.07477\n",
      "epochs [159/256], cost:38.00s train_loss: 0.53539 val_loss: 0.06029\n",
      "epochs [160/256], cost:38.00s train_loss: 0.52875 val_loss: 0.05695\n",
      "epochs [161/256], cost:39.00s train_loss: 0.49290 val_loss: 0.05564\n",
      "epochs [162/256], cost:39.00s train_loss: 0.49181 val_loss: 0.05905\n",
      "epochs [163/256], cost:38.00s train_loss: 0.48823 val_loss: 0.05665\n",
      "epochs [164/256], cost:38.00s train_loss: 0.47998 val_loss: 0.05666\n",
      "epochs [165/256], cost:39.00s train_loss: 0.47556 val_loss: 0.05214\n",
      "epochs [166/256], cost:38.00s train_loss: 0.46986 val_loss: 0.05279\n",
      "epochs [167/256], cost:38.00s train_loss: 0.47172 val_loss: 0.06257\n",
      "epochs [168/256], cost:38.00s train_loss: 0.49550 val_loss: 0.06018\n",
      "epochs [169/256], cost:39.00s train_loss: 0.48578 val_loss: 0.05144\n",
      "epochs [170/256], cost:38.00s train_loss: 0.46187 val_loss: 0.05967\n",
      "epochs [171/256], cost:38.00s train_loss: 0.46867 val_loss: 0.05222\n",
      "epochs [172/256], cost:38.00s train_loss: 0.47770 val_loss: 0.06724\n",
      "epochs [173/256], cost:38.00s train_loss: 0.51290 val_loss: 0.05334\n",
      "epochs [174/256], cost:38.00s train_loss: 0.47232 val_loss: 0.07378\n",
      "epochs [175/256], cost:38.00s train_loss: 0.49215 val_loss: 0.06438\n",
      "epochs [176/256], cost:38.00s train_loss: 0.49147 val_loss: 0.05692\n",
      "epochs [177/256], cost:38.00s train_loss: 0.50543 val_loss: 0.05783\n",
      "epochs [178/256], cost:38.00s train_loss: 0.50869 val_loss: 0.05279\n",
      "epochs [179/256], cost:38.00s train_loss: 0.46501 val_loss: 0.05846\n",
      "epochs [180/256], cost:39.00s train_loss: 0.44682 val_loss: 0.05004\n",
      "epochs [181/256], cost:39.00s train_loss: 0.43340 val_loss: 0.04924\n",
      "epochs [182/256], cost:39.00s train_loss: 0.44458 val_loss: 0.04851\n",
      "epochs [183/256], cost:38.00s train_loss: 0.43173 val_loss: 0.05461\n",
      "epochs [184/256], cost:38.00s train_loss: 0.44191 val_loss: 0.05327\n",
      "epochs [185/256], cost:39.00s train_loss: 0.42806 val_loss: 0.04788\n",
      "epochs [186/256], cost:38.00s train_loss: 0.44645 val_loss: 0.05168\n",
      "epochs [187/256], cost:39.00s train_loss: 0.42145 val_loss: 0.04868\n",
      "epochs [188/256], cost:46.00s train_loss: 0.42636 val_loss: 0.05001\n",
      "epochs [189/256], cost:46.00s train_loss: 0.42251 val_loss: 0.04908\n",
      "epochs [190/256], cost:46.00s train_loss: 0.42081 val_loss: 0.04869\n",
      "epochs [191/256], cost:46.00s train_loss: 0.43472 val_loss: 0.05600\n",
      "epochs [192/256], cost:46.00s train_loss: 0.44010 val_loss: 0.05178\n",
      "epochs [193/256], cost:46.00s train_loss: 0.43883 val_loss: 0.04615\n",
      "epochs [194/256], cost:46.00s train_loss: 0.41504 val_loss: 0.04873\n",
      "epochs [195/256], cost:46.00s train_loss: 0.40565 val_loss: 0.04811\n",
      "epochs [196/256], cost:46.00s train_loss: 0.39958 val_loss: 0.04477\n",
      "epochs [197/256], cost:47.00s train_loss: 0.39769 val_loss: 0.04574\n",
      "epochs [198/256], cost:46.00s train_loss: 0.39538 val_loss: 0.04593\n",
      "epochs [199/256], cost:46.00s train_loss: 0.39534 val_loss: 0.04596\n",
      "epochs [200/256], cost:46.00s train_loss: 0.39916 val_loss: 0.04693\n",
      "epochs [201/256], cost:47.00s train_loss: 0.38534 val_loss: 0.04405\n",
      "epochs [202/256], cost:46.00s train_loss: 0.40008 val_loss: 0.04456\n",
      "epochs [203/256], cost:46.00s train_loss: 0.39343 val_loss: 0.04564\n",
      "epochs [204/256], cost:46.00s train_loss: 0.39290 val_loss: 0.04453\n",
      "epochs [205/256], cost:45.00s train_loss: 0.37719 val_loss: 0.04564\n",
      "epochs [206/256], cost:46.00s train_loss: 0.38712 val_loss: 0.04495\n",
      "epochs [207/256], cost:46.00s train_loss: 0.38621 val_loss: 0.04641\n",
      "epochs [208/256], cost:46.00s train_loss: 0.38835 val_loss: 0.04576\n",
      "epochs [209/256], cost:47.00s train_loss: 0.39096 val_loss: 0.04364\n",
      "epochs [210/256], cost:47.00s train_loss: 0.37766 val_loss: 0.04346\n",
      "epochs [211/256], cost:47.00s train_loss: 0.37298 val_loss: 0.04320\n",
      "epochs [212/256], cost:47.00s train_loss: 0.37302 val_loss: 0.04318\n",
      "epochs [213/256], cost:47.00s train_loss: 0.37244 val_loss: 0.04221\n",
      "epochs [214/256], cost:45.00s train_loss: 0.37876 val_loss: 0.04311\n",
      "epochs [215/256], cost:47.00s train_loss: 0.36772 val_loss: 0.04411\n",
      "epochs [216/256], cost:47.00s train_loss: 0.36642 val_loss: 0.04030\n",
      "epochs [217/256], cost:45.00s train_loss: 0.36064 val_loss: 0.04261\n",
      "epochs [218/256], cost:45.00s train_loss: 0.36425 val_loss: 0.04236\n",
      "epochs [219/256], cost:46.00s train_loss: 0.35731 val_loss: 0.04343\n",
      "epochs [220/256], cost:47.00s train_loss: 0.35568 val_loss: 0.04191\n",
      "epochs [221/256], cost:46.00s train_loss: 0.35629 val_loss: 0.04186\n",
      "epochs [222/256], cost:46.00s train_loss: 0.34985 val_loss: 0.04236\n",
      "epochs [223/256], cost:46.00s train_loss: 0.35091 val_loss: 0.04214\n",
      "epochs [224/256], cost:46.00s train_loss: 0.35472 val_loss: 0.04411\n",
      "epochs [225/256], cost:46.00s train_loss: 0.35478 val_loss: 0.04263\n",
      "epochs [226/256], cost:46.00s train_loss: 0.35167 val_loss: 0.04268\n",
      "epochs [227/256], cost:46.00s train_loss: 0.34836 val_loss: 0.04130\n",
      "epochs [228/256], cost:47.00s train_loss: 0.34266 val_loss: 0.03910\n",
      "epochs [229/256], cost:46.00s train_loss: 0.34391 val_loss: 0.04202\n",
      "epochs [230/256], cost:46.00s train_loss: 0.35249 val_loss: 0.04063\n",
      "epochs [231/256], cost:46.00s train_loss: 0.34073 val_loss: 0.04105\n",
      "epochs [232/256], cost:47.00s train_loss: 0.34574 val_loss: 0.03966\n",
      "epochs [233/256], cost:46.00s train_loss: 0.33635 val_loss: 0.04092\n",
      "epochs [234/256], cost:46.00s train_loss: 0.33454 val_loss: 0.03876\n",
      "epochs [235/256], cost:47.00s train_loss: 0.33198 val_loss: 0.03832\n",
      "epochs [236/256], cost:47.00s train_loss: 0.33353 val_loss: 0.03766\n",
      "epochs [237/256], cost:46.00s train_loss: 0.32772 val_loss: 0.03898\n",
      "epochs [238/256], cost:45.00s train_loss: 0.32870 val_loss: 0.03825\n",
      "epochs [239/256], cost:46.00s train_loss: 0.32663 val_loss: 0.03794\n",
      "epochs [240/256], cost:46.00s train_loss: 0.33035 val_loss: 0.04049\n",
      "epochs [241/256], cost:46.00s train_loss: 0.32594 val_loss: 0.03718\n",
      "epochs [242/256], cost:47.00s train_loss: 0.32318 val_loss: 0.03641\n",
      "epochs [243/256], cost:46.00s train_loss: 0.32113 val_loss: 0.03901\n",
      "epochs [244/256], cost:46.00s train_loss: 0.32355 val_loss: 0.03730\n",
      "epochs [245/256], cost:46.00s train_loss: 0.31886 val_loss: 0.03768\n",
      "epochs [246/256], cost:46.00s train_loss: 0.31589 val_loss: 0.03859\n",
      "epochs [247/256], cost:46.00s train_loss: 0.31570 val_loss: 0.03686\n",
      "epochs [248/256], cost:46.00s train_loss: 0.31382 val_loss: 0.03725\n",
      "epochs [249/256], cost:46.00s train_loss: 0.31467 val_loss: 0.03739\n",
      "epochs [250/256], cost:47.00s train_loss: 0.31620 val_loss: 0.03578\n",
      "epochs [251/256], cost:46.00s train_loss: 0.31220 val_loss: 0.03610\n",
      "epochs [252/256], cost:47.00s train_loss: 0.31071 val_loss: 0.03525\n",
      "epochs [253/256], cost:46.00s train_loss: 0.31284 val_loss: 0.03577\n",
      "epochs [254/256], cost:46.00s train_loss: 0.31089 val_loss: 0.03713\n",
      "epochs [255/256], cost:46.00s train_loss: 0.30972 val_loss: 0.03496\n",
      "epochs [256/256], cost:47.00s train_loss: 0.30967 val_loss: 0.03516\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "full_train_index = [*range(0, len(X_wide_train))]\n",
    "\n",
    "\n",
    "total_train_loss_list = [] \n",
    "total_val_loss_list = [] \n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    starttime = datetime.datetime.now()\n",
    "    train_index, val_index, _, _, = train_test_split(full_train_index,full_train_index,test_size=0.1)\n",
    "    train_dataset = torch.utils.data.DataLoader(\n",
    "        TrainLoader(X_wide_train[train_index], X_deep_train[train_index], y_train[train_index]), \n",
    "                                                 batch_size=batch_size,)\n",
    "    val_dataset = torch.utils.data.DataLoader(\n",
    "        TrainLoader(X_wide_train[val_index], X_deep_train[val_index], y_train[val_index]), \n",
    "                                                 batch_size=batch_size,)\n",
    "    # training\n",
    "    total_train_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(train_dataset):\n",
    "        since_batch = time.time()\n",
    "        if torch.cuda.is_available():\n",
    "            net.cuda()\n",
    "            # X_wide_train_cuda = batch_x[0].float().cuda()\n",
    "            # X_deep_train_cuda = batch_x[1].float().cuda()\n",
    "            X_wide_train_cuda = batch_x[0].to(torch.complex128).cuda()\n",
    "            X_deep_train_cuda = batch_x[1].to(torch.complex128).cuda()\n",
    "                \n",
    "            y_train_cuda = batch_y.cuda()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        pred_y = net(X_wide_train_cuda, X_deep_train_cuda)\n",
    "        loss = criterion(pred_y, y_train_cuda)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # print(f\"Step [{step+1}/{len(train_dataset)}], batch time: {time.time() - since_batch:.2f}, train_loss: {loss.item()}\")\n",
    "\n",
    "    # validation\n",
    "    total_val_loss = 0\n",
    "    for _,(batch_val_x, batch_val_y) in enumerate(val_dataset):\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            X_wide_val_cuda = batch_val_x[0].float().cuda()\n",
    "            X_deep_val_cuda = batch_val_x[1].float().cuda()\n",
    "            y_val_cuda = batch_val_y.cuda()\n",
    "        \n",
    "        pred_y = net(X_wide_val_cuda, X_deep_val_cuda)\n",
    "        val_loss = criterion(pred_y, y_val_cuda)\n",
    "        total_val_loss += val_loss.item()\n",
    "    \n",
    "        # print statistics\n",
    "    if min_val_loss > total_val_loss:\n",
    "        torch.save(net.state_dict(), model_name)\n",
    "        min_val_loss = total_val_loss\n",
    "    endtime = datetime.datetime.now()\n",
    "    print('epochs [%d/%d], cost:%.2fs train_loss: %.5f val_loss: %.5f' % \n",
    "          (epoch + 1, epochs, (endtime-starttime).seconds, total_train_loss, total_val_loss))\n",
    "\n",
    "    total_train_loss_list.append(total_train_loss)\n",
    "    total_val_loss_list.append(total_val_loss)\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_938526/1928465884.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(model_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.load_state_dict(torch.load(model_name))\n",
    "years = test[5].unique()\n",
    "test_list = []\n",
    "\n",
    "for year in years:\n",
    "    temp = test[test[5]==year]\n",
    "    temp = temp.reset_index(drop=True)\n",
    "    test_list.append(temp)\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 年:\n",
      "len(tid) =  908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(pred_lat) = 908\n",
      "avg lat: 0.9387572965958048\n",
      "avg long: 1.2682190143064231\n",
      "avg distance error: 177.25748232018623\n",
      "2016 年:\n",
      "len(tid) =  489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(pred_lat) = 489\n",
      "avg lat: 0.8768379909616795\n",
      "avg long: 1.028579577736571\n",
      "avg distance error: 155.14789132982375\n",
      "2017 年:\n",
      "len(tid) =  544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(pred_lat) = 544\n",
      "avg lat: 0.935209140181541\n",
      "avg long: 1.1554999239304504\n",
      "avg distance error: 168.95143279158262\n",
      "2018 年:\n",
      "len(tid) =  806\n",
      "len(pred_lat) = 806\n",
      "avg lat: 0.9458796911736569\n",
      "avg long: 1.186380807578417\n",
      "avg distance error: 170.38627197423966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home2/chenyuv2/anaconda3/envs/qttp/lib/python3.9/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tid_list = []\n",
    "time_list = [] \n",
    "pred_lat_list = []\n",
    "pred_long_list = [] \n",
    "true_lat_list = [] \n",
    "true_long_list = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for year, _test in zip(years, test_list):\n",
    "\n",
    "        print(year, '年:')\n",
    "        # print(\"TID \", _test.loc[:,1])\n",
    "        y_test_lat = _test.loc[:,3]\n",
    "        \n",
    "        y_test_long = _test.loc[:,4]\n",
    "        \n",
    "        X_wide_test = X_wide_scaler.transform(_test.loc[:,6:])\n",
    "\n",
    "        final_test_list = []\n",
    "        for ahead_time in ahead_times:\n",
    "            year_test_list = []\n",
    "            for pressure in pressures:\n",
    "                scaler_name = reanalysis_type +str(pressure) + str(ahead_time)\n",
    "                X_deep = reanalysis_test_dict[scaler_name][reanalysis_test_dict[scaler_name][0].isin(_test[0].unique())].loc[:,5:]\n",
    "                X_deep = X_deep_scaler_dict[scaler_name].transform(X_deep)\n",
    "                X_deep_final = X_deep.reshape(-1, 1, 1, 31, 31)\n",
    "                year_test_list.append(X_deep_final)\n",
    "            X_deep_temp = np.concatenate(year_test_list, axis=2)\n",
    "            final_test_list.append(X_deep_temp)\n",
    "        X_deep_test = np.concatenate(final_test_list, axis=1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            X_wide_test = Variable(torch.from_numpy(X_wide_test).float().cuda())\n",
    "            X_deep_test = Variable(torch.from_numpy(X_deep_test).float().cuda())\n",
    "\n",
    "        \n",
    "        tid  = _test.loc[:,1]\n",
    "        time_ = _test.loc[:,2]\n",
    "        print(\"len(tid) = \",len(tid))\n",
    "        pred = net(X_wide_test, X_deep_test)\n",
    "\n",
    "        pred = y_scaler.inverse_transform(pred.cpu().detach().numpy())\n",
    "\n",
    "        pred_lat = pred[:,0]\n",
    "        pred_long = pred[:,1]\n",
    "        \n",
    "        print(\"len(pred_lat) =\", len(pred_lat))\n",
    "        true_lat = y_test_lat\n",
    "        true_long = y_test_long\n",
    "\n",
    "        diff_lat = np.abs(pred_lat - true_lat)\n",
    "        diff_long = np.abs(pred_long - true_long)\n",
    "\n",
    "        print('avg lat:', sum(diff_lat)/len(diff_lat))\n",
    "        print('avg long:', sum(diff_long)/len(diff_long))\n",
    "\n",
    "        sum_error = []\n",
    "        for i in range(0, len(pred_lat)):\n",
    "            sum_error.append(great_circle((pred_lat[i], pred_long[i]), (true_lat[i], true_long[i])).kilometers)\n",
    "\n",
    "        print('avg distance error:', sum(sum_error)/len(sum_error))\n",
    "        \n",
    "        tid_list.append(tid)\n",
    "        time_list.append(time_)\n",
    "        pred_lat_list.append(pred_lat)\n",
    "        pred_long_list.append(pred_long)\n",
    "        true_lat_list.append(true_lat)\n",
    "        true_long_list.append(true_long)\n",
    "        \n",
    "\n",
    "tid_list_ =  [item for sublist in tid_list for item in sublist]\n",
    "time_list_ =  [item for sublist in time_list for item in sublist]\n",
    "pred_lat_list_ =  [item for sublist in pred_lat_list for item in sublist]\n",
    "pred_long_list_ =  [item for sublist in pred_long_list for item in sublist]\n",
    "true_lat_list_ =  [item for sublist in true_lat_list for item in sublist]\n",
    "true_long_list_ =  [item for sublist in true_long_list for item in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_938526/142811645.py:1: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  id_key = pd.read_csv('../data/raw.csv', header=None)\n"
     ]
    }
   ],
   "source": [
    "id_key = pd.read_csv('../data/raw.csv', header=None)\n",
    "track_data = [] \n",
    "\n",
    "for i in range(len(tid_list_)):\n",
    "\n",
    "    if len(id_key[id_key[0] == str(tid_list_[i])][11].unique()) == 0:\n",
    "\n",
    "        track_data.append([\n",
    "            tid_list_[i], \n",
    "            id_key[id_key[0] == tid_list_[i]][11].unique()[0],\n",
    "            time_list_[i],\n",
    "            true_lat_list_[i],\n",
    "            true_long_list_[i],\n",
    "            pred_lat_list_[i],\n",
    "            pred_long_list_[i]\n",
    "            ])\n",
    "        \n",
    "    else:\n",
    "\n",
    "        track_data.append([\n",
    "            tid_list_[i], \n",
    "            id_key[id_key[0] == str(tid_list_[i])][11].unique()[0],\n",
    "            time_list_[i],\n",
    "            true_lat_list_[i],\n",
    "            true_long_list_[i],\n",
    "            pred_lat_list_[i],\n",
    "            pred_long_list_[i]\n",
    "            ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been written to ../results/QPA_track_data/track_data_QPA_ck_64_qnn_depth_20.csv\n"
     ]
    }
   ],
   "source": [
    "# Save predicted trajectory data in the testing dataset\n",
    "import csv\n",
    "\n",
    "file_path = \"../results/QPA_track_data/track_data_QPA_ck_64_qnn_depth_20.csv\"\n",
    "# Define the column headers\n",
    "headers = [\"TID\", \"KEY\", \"TIME\", \"LAT\", \"LONG\", \"PRED_LAT\", \"PRED_LONG\"] \n",
    "\n",
    "# Write to CSV\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writerow(headers)\n",
    "    \n",
    "    # Write the data rows\n",
    "    writer.writerows(track_data)\n",
    "\n",
    "print(f\"CSV file has been written to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
